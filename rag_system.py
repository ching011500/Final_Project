"""
RAG ç³»çµ±ï¼šå°‡èª²ç¨‹è³‡æ–™å‘é‡åŒ–ä¸¦å»ºç«‹å‘é‡è³‡æ–™åº«
ä½¿ç”¨ ChromaDB ä½œç‚ºå‘é‡è³‡æ–™åº«ï¼ŒOpenAI Embeddings é€²è¡Œå‘é‡åŒ–
æ”¯æ´å–®è¡¨å’Œå¤šè¡¨çµæ§‹
"""
import sqlite3
import json
import os
from typing import List, Dict, Optional
from dotenv import load_dotenv

# è¼‰å…¥ç’°å¢ƒè®Šæ•¸
load_dotenv()

import chromadb
from chromadb.config import Settings
from openai import OpenAI
from rank_bm25 import BM25Okapi
import jieba

class CourseRAGSystem:
    def __init__(self, db_path: str = "ntpu_courses.db", collection_name: str = "ntpu_courses", use_multi_table: bool = False):
        """
        åˆå§‹åŒ– RAG ç³»çµ±
        
        Args:
            db_path: SQLite è³‡æ–™åº«è·¯å¾‘
            collection_name: ChromaDB collection åç¨±
            use_multi_table: æ˜¯å¦ä½¿ç”¨å¤šè¡¨çµæ§‹ï¼ˆé è¨­ Falseï¼Œä½¿ç”¨å–®è¡¨ coursesï¼‰
        """
        self.db_path = db_path
        self.collection_name = collection_name
        self.use_multi_table = use_multi_table
        
        # åˆå§‹åŒ– OpenAI client (éœ€è¦è¨­å®š OPENAI_API_KEY ç’°å¢ƒè®Šæ•¸)
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            raise ValueError("è«‹è¨­å®š OPENAI_API_KEY ç’°å¢ƒè®Šæ•¸")
        self.openai_client = OpenAI(api_key=api_key)
        
        # åˆå§‹åŒ– ChromaDB
        self.chroma_client = chromadb.PersistentClient(
            path="./chroma_db",
            settings=Settings(anonymized_telemetry=False)
        )
        
        # å–å¾—æˆ–å»ºç«‹ collection
        try:
            self.collection = self.chroma_client.get_collection(name=collection_name)
            print(f"âœ… å·²è¼‰å…¥ç¾æœ‰çš„ collection: {collection_name}")
        except:
            self.collection = self.chroma_client.create_collection(
                name=collection_name,
                metadata={"description": "NTPU Courses RAG System"}
            )
            print(f"âœ… å·²å»ºç«‹æ–°çš„ collection: {collection_name}")
        
        # BM25 ç´¢å¼•ï¼ˆå»¶é²åˆå§‹åŒ–ï¼‰
        self.bm25_index = None
        self.bm25_documents = []  # å„²å­˜æ‰€æœ‰æ–‡ä»¶ç”¨æ–¼ BM25
        self.bm25_doc_ids = []  # å„²å­˜æ–‡ä»¶ ID å°æ‡‰é—œä¿‚
        
        # æ··åˆæª¢ç´¢æ¬Šé‡ï¼ˆå¯èª¿æ•´ï¼‰
        self.embedding_weight = 0.6  # Embedding æ¬Šé‡
        self.bm25_weight = 0.4  # BM25 æ¬Šé‡
    
    def _load_courses_from_db(self) -> List[Dict]:
        """
        å¾è³‡æ–™åº«è¼‰å…¥èª²ç¨‹è³‡æ–™
        
        Returns:
            èª²ç¨‹è³‡æ–™åˆ—è¡¨
        """
        conn = sqlite3.connect(self.db_path)
        conn.row_factory = sqlite3.Row
        cur = conn.cursor()
        
        if self.use_multi_table:
            # ä½¿ç”¨å¤šè¡¨çµæ§‹ï¼ˆå¾ course_full_view è¦–åœ–ï¼‰
            print("ğŸ“– å¾å¤šè¡¨çµæ§‹è¼‰å…¥èª²ç¨‹è³‡æ–™...")
            cur.execute("""
                SELECT DISTINCT
                    c.yearterm,
                    c.serial,
                    c.name,
                    c.note,
                    c.category,
                    c.credit,
                    c.hours,
                    c.language,
                    c.schedule,
                    c.addable,
                    c.add_limit,
                    c.total_limit,
                    c.enrolled,
                    c.syllabus_url,
                    c.limit_url,
                    c.limits_json,
                    c.edu_type,
                    c.crawl_time,
                    GROUP_CONCAT(DISTINCT d.name) as dept,
                    GROUP_CONCAT(DISTINCT t.name) as teacher,
                    GROUP_CONCAT(DISTINCT cg.grade || '|' || cg.required) as grade_required,
                    MAX(cg.grade_required_mapping) as grade_required_mapping
                FROM courses_normalized c
                LEFT JOIN course_departments cd ON c.yearterm = cd.yearterm 
                    AND c.serial = cd.serial 
                    AND c.edu_type = cd.edu_type
                LEFT JOIN departments d ON cd.dept_id = d.id
                LEFT JOIN course_teachers ct ON c.yearterm = ct.yearterm 
                    AND c.serial = ct.serial 
                    AND c.edu_type = ct.edu_type
                LEFT JOIN teachers t ON ct.teacher_id = t.id
                LEFT JOIN course_grades cg ON c.yearterm = cg.yearterm 
                    AND c.serial = cg.serial 
                    AND c.edu_type = cg.edu_type
                GROUP BY c.yearterm, c.serial, c.edu_type
            """)
        else:
            # ä½¿ç”¨å–®è¡¨çµæ§‹ï¼ˆå¾ courses è¡¨ï¼‰
            print("ğŸ“– å¾å–®è¡¨çµæ§‹è¼‰å…¥èª²ç¨‹è³‡æ–™...")
            cur.execute("SELECT * FROM courses")
        
        courses = cur.fetchall()
        conn.close()
        
        # å°‡ Row ç‰©ä»¶è½‰æ›ç‚ºå­—å…¸
        courses_dict = []
        for course in courses:
            course_dict = dict(course)
            
            # è™•ç†å¤šè¡¨çµæ§‹çš„ grade å’Œ required
            if self.use_multi_table and 'grade_required' in course_dict:
                grade_required_str = course_dict.get('grade_required', '')
                if grade_required_str:
                    # è§£æ grade_required å­—ä¸²ï¼ˆæ ¼å¼ï¼šgrade1|required1,grade2|required2ï¼‰
                    parts = grade_required_str.split(',')
                    grades = []
                    requireds = []
                    for part in parts:
                        if '|' in part:
                            g, r = part.split('|', 1)
                            grades.append(g.strip())
                            requireds.append(r.strip())
                    
                    if grades and requireds:
                        course_dict['grade'] = '|'.join(grades)
                        course_dict['required'] = '|'.join(requireds)
            
            courses_dict.append(course_dict)
        
        return courses_dict
    
    def _create_course_text(self, course: Dict) -> str:
        """
        å°‡èª²ç¨‹è³‡æ–™è½‰æ›æˆé©åˆæª¢ç´¢çš„æ–‡å­—æ ¼å¼
        
        Args:
            course: èª²ç¨‹è³‡æ–™å­—å…¸
            
        Returns:
            æ ¼å¼åŒ–çš„èª²ç¨‹æ–‡å­—æè¿°
        """
        text_parts = []
        
        # åŸºæœ¬è³‡è¨Š
        text_parts.append(f"èª²ç¨‹åç¨±ï¼š{course.get('name', '')}")
        text_parts.append(f"èª²ç¨‹ä»£ç¢¼ï¼š{course.get('serial', '')}")
        text_parts.append(f"å­¸å¹´åº¦å­¸æœŸï¼š{course.get('yearterm', '')}")
        text_parts.append(f"ç³»æ‰€ï¼š{course.get('dept', '')}")
        
        # å¹´ç´šè³‡è¨Š
        grade = course.get('grade', '')
        if grade:
            text_parts.append(f"å¹´ç´šï¼š{grade}")
        
        # å¿…é¸ä¿®è³‡è¨Šï¼ˆé‡é»åŠ å¼·ï¼‰
        # å„ªå…ˆä½¿ç”¨ grade_required_mapping JSON æ¬„ä½
        mapping_json = course.get('grade_required_mapping', '')
        if mapping_json:
            try:
                mapping_data = json.loads(mapping_json)
                mapping = mapping_data.get('mapping', [])
                
                if mapping:
                    text_parts.append(f"å¹´ç´šçµ„åˆ¥èˆ‡å¿…é¸ä¿®å°æ‡‰ï¼š")
                    for grade_item, required_item in mapping:
                        if 'å¿…' in required_item:
                            text_parts.append(f"  {grade_item}ï¼šå¿…ä¿®èª²ç¨‹")
                        elif 'é¸' in required_item:
                            text_parts.append(f"  {grade_item}ï¼šé¸ä¿®èª²ç¨‹")
                        else:
                            text_parts.append(f"  {grade_item}ï¼š{required_item}")
                    
                    # çµ±è¨ˆè³‡è¨Š
                    required_groups = mapping_data.get('required_groups', [])
                    elective_groups = mapping_data.get('elective_groups', [])
                    if required_groups:
                        text_parts.append(f"å¿…ä¿®çµ„åˆ¥ï¼š{', '.join(required_groups[:10])}")  # åªé¡¯ç¤ºå‰10å€‹
                    if elective_groups:
                        text_parts.append(f"é¸ä¿®çµ„åˆ¥ï¼š{', '.join(elective_groups[:10])}")  # åªé¡¯ç¤ºå‰10å€‹
            except:
                pass
        
        # å¦‚æœæ²’æœ‰ JSON æ¬„ä½ï¼Œä½¿ç”¨å‚³çµ±æ–¹å¼
        required = course.get('required', '')
        if required:
            # å°‡å¿…é¸ä¿®è³‡è¨Šæ›´æ˜ç¢ºåœ°æ¨™ç¤º
            if 'å¿…' in required:
                text_parts.append(f"å¿…é¸ä¿®ï¼šå¿…ä¿®èª²ç¨‹")
                text_parts.append(f"èª²ç¨‹é¡å‹ï¼šå¿…ä¿®")
            elif 'é¸' in required:
                text_parts.append(f"å¿…é¸ä¿®ï¼šé¸ä¿®èª²ç¨‹")
                text_parts.append(f"èª²ç¨‹é¡å‹ï¼šé¸ä¿®")
            else:
                text_parts.append(f"å¿…é¸ä¿®ï¼š{required}")
        
        text_parts.append(f"æˆèª²æ•™å¸«ï¼š{course.get('teacher', '')}")
        
        # èª²ç¨‹é¡åˆ¥
        category = course.get('category', '')
        if category:
            text_parts.append(f"èª²ç¨‹é¡åˆ¥ï¼š{category}")
        
        text_parts.append(f"å­¸åˆ†æ•¸ï¼š{course.get('credit', '')}")
        
        # æ™‚æ•¸
        hours = course.get('hours', '')
        if hours:
            text_parts.append(f"æ™‚æ•¸ï¼š{hours}")
        
        # æˆèª²èªè¨€
        language = course.get('language', '')
        if language:
            text_parts.append(f"æˆèª²èªè¨€ï¼š{language}")
        
        text_parts.append(f"ä¸Šèª²æ™‚é–“ï¼š{course.get('schedule', '')}")
        text_parts.append(f"å­¸åˆ¶ï¼š{course.get('edu_type', '')}")
        
        if course.get('note'):
            text_parts.append(f"å‚™è¨»ï¼š{course.get('note', '')}")
        
        # èª²ç¨‹é™åˆ¶
        limits_json = course.get('limits_json', '')
        if limits_json:
            try:
                limits = json.loads(limits_json)
                if limits:
                    limits_text = "èª²ç¨‹é™åˆ¶ï¼š"
                    for key, value in limits.items():
                        limits_text += f"{key}ï¼š{value}ï¼›"
                    text_parts.append(limits_text)
            except:
                pass
        
        # é¸èª²è³‡è¨Š
        text_parts.append(f"å¯åŠ é¸ï¼š{course.get('addable', '')}")
        text_parts.append(f"åŠ é¸äººæ•¸ä¸Šé™ï¼š{course.get('add_limit', '')}")
        text_parts.append(f"ç¸½äººæ•¸ä¸Šé™ï¼š{course.get('total_limit', '')}")
        text_parts.append(f"å·²é¸äººæ•¸ï¼š{course.get('enrolled', '')}")
        
        return "\n".join(text_parts)
    
    def _get_embedding(self, text: str) -> List[float]:
        """
        ä½¿ç”¨ OpenAI å–å¾—æ–‡å­—å‘é‡
        
        Args:
            text: è¦å‘é‡åŒ–çš„æ–‡å­—
            
        Returns:
            å‘é‡åˆ—è¡¨
        """
        response = self.openai_client.embeddings.create(
            model="text-embedding-3-small",
            input=text
        )
        return response.data[0].embedding
    
    def build_vector_database(self):
        """
        å¾ SQLite è³‡æ–™åº«è®€å–èª²ç¨‹è³‡æ–™ï¼Œå»ºç«‹å‘é‡è³‡æ–™åº«
        """
        print("ğŸ“š é–‹å§‹å»ºç«‹å‘é‡è³‡æ–™åº«...")
        print(f"ğŸ“‹ ä½¿ç”¨{'å¤šè¡¨' if self.use_multi_table else 'å–®è¡¨'}çµæ§‹")
        
        # è¼‰å…¥èª²ç¨‹è³‡æ–™
        courses = self._load_courses_from_db()
        
        if not courses:
            print("âŒ æ²’æœ‰æ‰¾åˆ°èª²ç¨‹è³‡æ–™")
            if self.use_multi_table:
                print("ğŸ’¡ æç¤ºï¼šå¤šè¡¨çµæ§‹å¯èƒ½æ²’æœ‰è³‡æ–™ï¼Œè«‹å…ˆåŸ·è¡Œï¼špython create_multi_tables.py migrate")
            return
        
        print(f"ğŸ“– å…±æ‰¾åˆ° {len(courses)} ç­†èª²ç¨‹è³‡æ–™")
        
        # æª¢æŸ¥ collection æ˜¯å¦å·²æœ‰è³‡æ–™
        existing_count = self.collection.count()
        if existing_count > 0:
            print(f"âš ï¸  Collection ä¸­å·²æœ‰ {existing_count} ç­†è³‡æ–™")
            response = input("æ˜¯å¦è¦é‡æ–°å»ºç«‹ï¼Ÿ(y/n): ")
            if response.lower() == 'y':
                # åˆªé™¤ç¾æœ‰ collection ä¸¦é‡æ–°å»ºç«‹
                self.chroma_client.delete_collection(name=self.collection_name)
                self.collection = self.chroma_client.create_collection(
                    name=self.collection_name,
                    metadata={"description": "NTPU Courses RAG System"}
                )
                print("âœ… å·²æ¸…é™¤èˆŠè³‡æ–™")
            else:
                print("âŒ å–æ¶ˆå»ºç«‹å‘é‡è³‡æ–™åº«")
                return
        
        # æ‰¹æ¬¡è™•ç†èª²ç¨‹è³‡æ–™
        batch_size = 100
        all_texts = []
        all_metadatas = []
        all_ids = []
        
        # å…ˆæº–å‚™æ‰€æœ‰è³‡æ–™
        print("ğŸ“ æº–å‚™èª²ç¨‹è³‡æ–™...")
        for idx, course_row in enumerate(courses):
            course = dict(course_row)
            
            # å»ºç«‹èª²ç¨‹æ–‡å­—æè¿°
            course_text = self._create_course_text(course)
            all_texts.append(course_text)
            
            # å»ºç«‹ metadataï¼ˆä¿ç•™åŸå§‹è³‡æ–™ä»¥ä¾¿å¾ŒçºŒä½¿ç”¨ï¼‰
            required = course.get('required', '')
            is_required = 'å¿…' in required if required else False
            
            # å–å¾— grade_required_mapping JSON æ¬„ä½ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            mapping_json = course.get('grade_required_mapping', '')
            
            metadata = {
                'serial': course.get('serial', ''),
                'name': course.get('name', ''),
                'dept': course.get('dept', ''),
                'teacher': course.get('teacher', ''),
                'yearterm': course.get('yearterm', ''),
                'edu_type': course.get('edu_type', ''),
                'credit': str(course.get('credit', '')),
                'schedule': course.get('schedule', ''),
                'required': required,  # åŠ å…¥å¿…é¸ä¿®è³‡è¨Š
                'is_required': 'æ˜¯' if is_required else 'å¦',  # æ˜ç¢ºæ¨™ç¤ºæ˜¯å¦ç‚ºå¿…ä¿®
                'grade': course.get('grade', ''),
            }
            
            # å¦‚æœæœ‰ grade_required_mappingï¼ŒåŠ å…¥ metadataï¼ˆä½† ChromaDB çš„ metadata å¯èƒ½ä¸æ”¯æ´å¤ªé•·çš„ JSONï¼‰
            # æˆ‘å€‘å¯ä»¥åªåŠ å…¥é—œéµè³‡è¨Š
            if mapping_json:
                try:
                    mapping_data = json.loads(mapping_json)
                    # åªåŠ å…¥å¿…è¦çš„è³‡è¨Šåˆ° metadataï¼ˆé¿å… metadata å¤ªå¤§ï¼‰
                    if mapping_data.get('required_groups'):
                        metadata['has_required_groups'] = 'æ˜¯'
                    if mapping_data.get('elective_groups'):
                        metadata['has_elective_groups'] = 'æ˜¯'
                    # æ³¨æ„ï¼šå®Œæ•´çš„ mapping_json æœƒå­˜åœ¨ document ä¸­ï¼Œå¯ä»¥å¾ document ä¸­æå–
                    metadata['grade_required_mapping'] = mapping_json  # å„²å­˜ JSON å­—ä¸²
                except:
                    pass
            
            all_metadatas.append(metadata)
            
            # å»ºç«‹å”¯ä¸€ ID
            course_id = f"{course.get('yearterm', '')}_{course.get('serial', '')}_{course.get('edu_type', '')}"
            all_ids.append(course_id)
        
        # æ‰¹æ¬¡è™•ç† embeddings ä¸¦åŠ å…¥ ChromaDB
        print("ğŸ”„ é–‹å§‹å‘é‡åŒ–ä¸¦å»ºç«‹å‘é‡è³‡æ–™åº«...")
        for i in range(0, len(all_texts), batch_size):
            batch_texts = all_texts[i:i+batch_size]
            batch_metadatas = all_metadatas[i:i+batch_size]
            batch_ids = all_ids[i:i+batch_size]
            
            print(f"ğŸ”„ è™•ç†ä¸­ï¼š{min(i+batch_size, len(all_texts))}/{len(all_texts)}")
            
            # æ‰¹æ¬¡å–å¾— embeddings
            batch_embeddings = []
            for text in batch_texts:
                embedding = self._get_embedding(text)
                batch_embeddings.append(embedding)
            
            # æ‰¹æ¬¡åŠ å…¥ ChromaDB
            self.collection.add(
                embeddings=batch_embeddings,
                documents=batch_texts,
                metadatas=batch_metadatas,
                ids=batch_ids
            )
            print(f"âœ… å·²åŠ å…¥ {len(batch_texts)} ç­†è³‡æ–™åˆ°å‘é‡è³‡æ–™åº«")
        
        print(f"ğŸ‰ å‘é‡è³‡æ–™åº«å»ºç«‹å®Œæˆï¼å…± {self.collection.count()} ç­†è³‡æ–™")
        
        # å»ºç«‹ BM25 ç´¢å¼•
        print("ğŸ”„ å»ºç«‹ BM25 ç´¢å¼•...")
        self._build_bm25_index(all_texts, all_ids)
        print("âœ… BM25 ç´¢å¼•å»ºç«‹å®Œæˆï¼")
    
    def _build_bm25_index(self, documents: List[str], doc_ids: List[str]):
        """
        å»ºç«‹ BM25 ç´¢å¼•
        
        Args:
            documents: æ–‡ä»¶åˆ—è¡¨
            doc_ids: æ–‡ä»¶ ID åˆ—è¡¨
        """
        # å„²å­˜æ–‡ä»¶ç”¨æ–¼ BM25
        self.bm25_documents = documents
        self.bm25_doc_ids = doc_ids
        
        # ä½¿ç”¨ jieba é€²è¡Œä¸­æ–‡åˆ†è©
        tokenized_docs = []
        for doc in documents:
            # ä½¿ç”¨ jieba åˆ†è©
            tokens = jieba.cut(doc)
            tokenized_docs.append(list(tokens))
        
        # å»ºç«‹ BM25 ç´¢å¼•
        self.bm25_index = BM25Okapi(tokenized_docs)
        print(f"âœ… BM25 ç´¢å¼•å·²å»ºç«‹ï¼Œå…± {len(tokenized_docs)} ç­†æ–‡ä»¶")
    
    def _tokenize_query(self, query: str) -> List[str]:
        """
        å°æŸ¥è©¢é€²è¡Œåˆ†è©
        
        Args:
            query: æŸ¥è©¢æ–‡å­—
            
        Returns:
            åˆ†è©å¾Œçš„åˆ—è¡¨
        """
        return list(jieba.cut(query))
    
    def search_courses(self, query: str, n_results: int = 5, use_hybrid: bool = True) -> List[Dict]:
        """
        æœå°‹ç›¸é—œèª²ç¨‹ï¼ˆæ”¯æ´æ··åˆæª¢ç´¢ï¼šBM25 + Embeddingï¼‰
        
        Args:
            query: ä½¿ç”¨è€…æŸ¥è©¢æ–‡å­—
            n_results: å›å‚³çµæœæ•¸é‡
            use_hybrid: æ˜¯å¦ä½¿ç”¨æ··åˆæª¢ç´¢ï¼ˆé è¨­ Trueï¼‰
            
        Returns:
            ç›¸é—œèª²ç¨‹åˆ—è¡¨
        """
        # å¦‚æœ BM25 ç´¢å¼•æœªå»ºç«‹ï¼Œå˜—è©¦å¾ç¾æœ‰è³‡æ–™å»ºç«‹
        if use_hybrid and self.bm25_index is None:
            self._try_load_bm25_index()
        
        if use_hybrid and self.bm25_index is not None:
            # ä½¿ç”¨æ··åˆæª¢ç´¢ï¼šBM25 + Embedding
            return self._hybrid_search(query, n_results)
        else:
            # åƒ…ä½¿ç”¨ Embedding æª¢ç´¢
            return self._embedding_search(query, n_results)
    
    def _try_load_bm25_index(self):
        """
        å˜—è©¦å¾ ChromaDB è¼‰å…¥è³‡æ–™ä¸¦å»ºç«‹ BM25 ç´¢å¼•
        """
        try:
            # å¾ ChromaDB å–å¾—æ‰€æœ‰æ–‡ä»¶
            all_results = self.collection.get()
            if all_results['documents']:
                documents = all_results['documents']
                doc_ids = all_results['ids']
                self._build_bm25_index(documents, doc_ids)
        except Exception as e:
            print(f"âš ï¸  ç„¡æ³•è¼‰å…¥ BM25 ç´¢å¼•ï¼š{e}")
    
    def _embedding_search(self, query: str, n_results: int) -> List[Dict]:
        """
        åƒ…ä½¿ç”¨ Embedding é€²è¡Œæª¢ç´¢
        
        Args:
            query: ä½¿ç”¨è€…æŸ¥è©¢æ–‡å­—
            n_results: å›å‚³çµæœæ•¸é‡
            
        Returns:
            ç›¸é—œèª²ç¨‹åˆ—è¡¨
        """
        # å–å¾—æŸ¥è©¢å‘é‡
        query_embedding = self._get_embedding(query)
        
        # åœ¨å‘é‡è³‡æ–™åº«ä¸­æœå°‹ï¼ˆæ“´å¤§æœå°‹ç¯„åœä»¥é€²è¡Œæ··åˆï¼‰
        search_n = n_results * 3 if self.bm25_index is not None else n_results
        
        results = self.collection.query(
            query_embeddings=[query_embedding],
            n_results=search_n
        )
        
        # æ ¼å¼åŒ–çµæœ
        courses = []
        if results['documents'] and len(results['documents'][0]) > 0:
            for i in range(len(results['documents'][0])):
                course_info = {
                    'document': results['documents'][0][i],
                    'metadata': results['metadatas'][0][i],
                    'distance': results['distances'][0][i] if 'distances' in results else None,
                    'similarity': 1 - results['distances'][0][i] if 'distances' in results and results['distances'][0][i] else 0,
                    'embedding_score': 1 - results['distances'][0][i] if 'distances' in results and results['distances'][0][i] else 0
                }
                courses.append(course_info)
        
        return courses
    
    def _hybrid_search(self, query: str, n_results: int) -> List[Dict]:
        """
        æ··åˆæª¢ç´¢ï¼šBM25 + Embedding
        
        Args:
            query: ä½¿ç”¨è€…æŸ¥è©¢æ–‡å­—
            n_results: å›å‚³çµæœæ•¸é‡
            
        Returns:
            ç›¸é—œèª²ç¨‹åˆ—è¡¨ï¼ˆæŒ‰æ··åˆåˆ†æ•¸æ’åºï¼‰
        """
        # 1. Embedding æª¢ç´¢ï¼ˆæ“´å¤§ç¯„åœï¼‰
        embedding_results = self._embedding_search(query, n_results * 3)
        
        # 2. BM25 æª¢ç´¢
        tokenized_query = self._tokenize_query(query)
        bm25_scores = self.bm25_index.get_scores(tokenized_query)
        
        # å»ºç«‹ BM25 åˆ†æ•¸æ˜ å°„ï¼ˆdoc_id -> scoreï¼‰
        bm25_score_map = {}
        for i, doc_id in enumerate(self.bm25_doc_ids):
            bm25_score_map[doc_id] = bm25_scores[i]
        
        # æ­£è¦åŒ– BM25 åˆ†æ•¸ï¼ˆ0-1 ç¯„åœï¼‰
        if len(bm25_scores) > 0:
            max_bm25 = float(max(bm25_scores))
            min_bm25 = float(min(bm25_scores))
            if max_bm25 > min_bm25:
                bm25_score_map = {
                    doc_id: (float(score) - min_bm25) / (max_bm25 - min_bm25)
                    for doc_id, score in bm25_score_map.items()
                }
            else:
                bm25_score_map = {doc_id: 0.0 for doc_id in bm25_score_map.keys()}
        
        # 3. åˆä½µçµæœä¸¦è¨ˆç®—æ··åˆåˆ†æ•¸
        # å»ºç«‹ document -> course_info æ˜ å°„
        course_map = {}
        for course in embedding_results:
            doc_id = f"{course['metadata'].get('yearterm', '')}_{course['metadata'].get('serial', '')}_{course['metadata'].get('edu_type', '')}"
            course['bm25_score'] = bm25_score_map.get(doc_id, 0.0)
            course_map[doc_id] = course
        
        # åŠ å…¥ BM25 é«˜åˆ†ä½† Embedding ä½åˆ†çš„çµæœ
        # æ‰¾å‡º BM25 å‰ n_results * 2 çš„çµæœ
        top_bm25_indices = sorted(range(len(bm25_scores)), key=lambda i: bm25_scores[i], reverse=True)[:n_results * 2]
        
        for idx in top_bm25_indices:
            doc_id = self.bm25_doc_ids[idx]
            if doc_id not in course_map:
                # å¾ ChromaDB å–å¾—å®Œæ•´è³‡è¨Š
                try:
                    chroma_results = self.collection.get(ids=[doc_id])
                    if chroma_results['documents']:
                        course_info = {
                            'document': chroma_results['documents'][0],
                            'metadata': chroma_results['metadatas'][0] if chroma_results['metadatas'] else {},
                            'distance': None,
                            'similarity': 0.0,
                            'embedding_score': 0.0,
                            'bm25_score': bm25_score_map.get(doc_id, 0.0)
                        }
                        course_map[doc_id] = course_info
                except:
                    pass
        
        # 4. è¨ˆç®—æ··åˆåˆ†æ•¸ä¸¦æ’åº
        for course in course_map.values():
            embedding_score = course.get('embedding_score', 0.0)
            bm25_score = course.get('bm25_score', 0.0)
            
            # æ··åˆåˆ†æ•¸ = weighted sum
            hybrid_score = self.embedding_weight * embedding_score + self.bm25_weight * bm25_score
            course['hybrid_score'] = hybrid_score
            course['similarity'] = hybrid_score  # æ›´æ–° similarity ç‚ºæ··åˆåˆ†æ•¸
        
        # 5. æŒ‰æ··åˆåˆ†æ•¸æ’åºä¸¦è¿”å›å‰ n_results
        sorted_courses = sorted(course_map.values(), key=lambda x: x['hybrid_score'], reverse=True)
        
        return sorted_courses[:n_results]


if __name__ == "__main__":
    import sys
    
    # æª¢æŸ¥æ˜¯å¦ä½¿ç”¨å¤šè¡¨çµæ§‹
    use_multi_table = False
    if len(sys.argv) > 1 and sys.argv[1] == "--multi-table":
        use_multi_table = True
        print("ğŸ“‹ ä½¿ç”¨å¤šè¡¨çµæ§‹")
    
    # åˆå§‹åŒ– RAG ç³»çµ±
    rag = CourseRAGSystem(use_multi_table=use_multi_table)
    
    # æª¢æŸ¥æ˜¯å¦éœ€è¦å»ºç«‹å‘é‡è³‡æ–™åº«
    existing_count = rag.collection.count()
    
    if existing_count == 0:
        print("\nğŸ“š å‘é‡è³‡æ–™åº«ç‚ºç©ºï¼Œé–‹å§‹å»ºç«‹å‘é‡è³‡æ–™åº«...")
        print("âš ï¸  æ³¨æ„ï¼šé€™å¯èƒ½éœ€è¦ä¸€äº›æ™‚é–“ï¼ˆç´„ 10-30 åˆ†é˜ï¼‰ï¼Œè¦–èª²ç¨‹æ•¸é‡è€Œå®š")
        print("âš ï¸  é€™æœƒç”¢ç”Ÿ OpenAI API è²»ç”¨ï¼Œè«‹ç¢ºèªæ‚¨çš„å¸³è™Ÿæœ‰è¶³å¤ é¡åº¦")
        response = input("\næ˜¯å¦ç¹¼çºŒï¼Ÿ(y/n): ")
        if response.lower() == 'y':
            rag.build_vector_database()
        else:
            print("âŒ å–æ¶ˆå»ºç«‹å‘é‡è³‡æ–™åº«")
            sys.exit(0)
    else:
        print(f"\nâœ… å‘é‡è³‡æ–™åº«å·²å­˜åœ¨ï¼Œå…±æœ‰ {existing_count} ç­†è³‡æ–™")
        print("ğŸ’¡ å¦‚æœè¦é‡æ–°å»ºç«‹ï¼Œè«‹åˆªé™¤ chroma_db ç›®éŒ„æˆ–åˆªé™¤ collection")
